         3381287 function calls (3335761 primitive calls) in 11.064 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     5000    1.386    0.000    1.386    0.000 {built-in method torch._C._nn.upsample_bilinear2d}
38354/33354    1.324    0.000    1.386    0.000 {method 'to' of 'torch._C._TensorBase' objects}
     6522    1.209    0.000    2.184    0.000 /vision/torchvision/transforms/functional_tensor.py:875(_scale_channel)
      821    0.621    0.001    0.621    0.001 {built-in method torch.grid_sampler}
10000/5000    0.515    0.000    0.547    0.000 {method 'flip' of 'torch._C._TensorBase' objects}
     6522    0.433    0.000    0.433    0.000 {built-in method torch.bincount}
     5000    0.311    0.000    0.311    0.000 {method 'div' of 'torch._C._TensorBase' objects}
 1422/711    0.290    0.000    0.293    0.000 {built-in method torch.where}
     5922    0.252    0.000    0.252    0.000 {built-in method torch.round}
    46018    0.218    0.000    1.955    0.000 /vision/torchvision/prototype/features/_feature.py:73(__torch_function__)
     5000    0.210    0.000    5.390    0.001 /vision/torchvision/prototype/transforms/_auto_augment.py:276(forward)
     1093    0.164    0.000    0.218    0.000 /vision/torchvision/transforms/functional_tensor.py:150(rgb_to_grayscale)
     5000    0.104    0.000    0.426    0.000 /vision/torchvision/prototype/transforms/_geometry.py:107(_get_params)
     7986    0.100    0.000    0.100    0.000 {method 'clamp' of 'torch._C._TensorBase' objects}
     1295    0.100    0.000    0.100    0.000 {method 'mul' of 'torch._C._TensorBase' objects}
     1194    0.099    0.000    0.343    0.000 /vision/torchvision/transforms/functional_tensor.py:264(_blend)
     5000    0.096    0.000    0.354    0.000 /usr/lib/python3.8/traceback.py:321(extract)
      711    0.095    0.000    0.095    0.000 {method 'ge' of 'torch._C._TensorBase' objects}
    19566    0.095    0.000    0.095    0.000 {built-in method torch.div}
20627/19806    0.093    0.000    0.096    0.000 {method 'view' of 'torch._C._TensorBase' objects}
    25000    0.092    0.000    0.092    0.000 {built-in method posix.stat}
    26153    0.092    0.000    0.092    0.000 {method 'as_subclass' of 'torch._C._TensorBase' objects}
    17015    0.090    0.000    0.090    0.000 {built-in method torch.rand}
     5000    0.090    0.000    0.813    0.000 /vision/torchvision/prototype/transforms/_transform.py:66(forward)
      821    0.087    0.000    0.087    0.000 {method 'bmm' of 'torch._C._TensorBase' objects}
     1317    0.086    0.000    0.086    0.000 {method 'sub' of 'torch._C._TensorBase' objects}
    15000    0.086    0.000    0.086    0.000 {built-in method torch.randint}
     5000    0.077    0.000    0.137    0.000 /usr/lib/python3.8/traceback.py:388(format)
     2174    0.074    0.000    0.074    0.000 {built-in method torch.stack}
     7689    0.071    0.000    0.071    0.000 {built-in method torch.tensor}
25000/5000    0.062    0.000   10.430    0.002 /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1184(_call_impl)
    13515    0.058    0.000    0.058    0.000 {built-in method torch.empty}
     6522    0.057    0.000    0.057    0.000 {built-in method torch.nn.functional.pad}
    12694    0.056    0.000    0.056    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}
   346770    0.053    0.000    0.053    0.000 {built-in method builtins.isinstance}
     5000    0.052    0.000   10.411    0.002 /vision/torchvision/prototype/transforms/_container.py:15(forward)
      101    0.051    0.001    0.051    0.001 {built-in method torch.conv2d}
     1642    0.048    0.000    0.048    0.000 {method 'copy_' of 'torch._C._TensorBase' objects}
     2174    0.048    0.000    2.289    0.001 /vision/torchvision/transforms/functional_tensor.py:897(<listcomp>)
     5000    0.045    0.000    0.736    0.000 /vision/torchvision/transforms/functional_tensor.py:68(convert_image_dtype)
    15000    0.045    0.000    4.760    0.000 /vision/torchvision/prototype/transforms/_transform.py:32(forward)
    18949    0.039    0.000    0.065    0.000 /vision/torchvision/transforms/functional_tensor.py:24(get_dimensions)
     6623    0.038    0.000    0.038    0.000 {method 'sum' of 'torch._C._TensorBase' objects}
21444/13222    0.037    0.000    0.078    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}
    30000    0.036    0.000    0.049    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:112(__init__)
     5000    0.035    0.000    2.465    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:106(resize_image_tensor)
     5000    0.035    0.000    0.131    0.000 /vision/torchvision/transforms/functional_tensor.py:132(crop)
     6522    0.035    0.000    0.035    0.000 {built-in method torch.cumsum}
   135000    0.034    0.000    0.085    0.000 /usr/lib/python3.8/traceback.py:285(line)
    25000    0.032    0.000    0.032    0.000 {built-in method torch._C._get_tracing_state}
    90000    0.031    0.000    0.031    0.000 {method 'format' of 'str' objects}
    30000    0.031    0.000    0.180    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:139(tree_flatten)
     5000    0.030    0.000    2.352    0.000 /vision/torchvision/transforms/functional_tensor.py:447(resize)
    46018    0.030    0.000    0.065    0.000 {built-in method builtins.all}
    30000    0.029    0.000    0.078    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:132(__init__)
      546    0.029    0.000    0.029    0.000 {method '__and__' of 'torch._C._TensorBase' objects}
     6347    0.028    0.000    0.028    0.000 {built-in method torch.exp}
    10000    0.027    0.000    0.064    0.000 /vision/torchvision/prototype/features/_image.py:126(image_size)
    49092    0.027    0.000    0.027    0.000 /vision/torchvision/prototype/features/_feature.py:144(shape)
    26153    0.027    0.000    0.119    0.000 /vision/torchvision/prototype/features/_image.py:102(new_like)
      821    0.027    0.000    0.218    0.000 /vision/torchvision/transforms/functional_tensor.py:581(_gen_affine_grid)
     5000    0.026    0.000    0.026    0.000 {function Random.seed at 0x7fd4c2ac8040}
     4368    0.026    0.000    0.026    0.000 {built-in method torch.linspace}
     5000    0.026    0.000    0.790    0.000 /vision/torchvision/transforms/functional.py:211(convert_image_dtype)
   266139    0.025    0.000    0.025    0.000 {built-in method builtins.len}
    30000    0.025    0.000    0.071    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:102(_is_leaf)
     5000    0.025    0.000    1.421    0.000 /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3765(interpolate)
    30000    0.025    0.000    0.028    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:86(_is_namedtuple_instance)
    15000    0.024    0.000    4.178    0.000 /vision/torchvision/prototype/transforms/_transform.py:38(<listcomp>)
    25000    0.024    0.000    0.118    0.000 /usr/lib/python3.8/linecache.py:53(checkcache)
      821    0.023    0.000    0.023    0.000 {method 'fill_' of 'torch._C._TensorBase' objects}
    10000    0.023    0.000    0.111    0.000 /vision/torchvision/prototype/transforms/functional/_meta.py:14(get_chw)
    45000    0.023    0.000    0.044    0.000 /usr/lib/python3.8/linecache.py:15(getline)
    92036    0.022    0.000    0.036    0.000 /vision/torchvision/prototype/features/_feature.py:101(<genexpr>)
    22694    0.022    0.000    0.022    0.000 {method 'item' of 'torch._C._TensorBase' objects}
      270    0.022    0.000    0.121    0.000 /vision/torchvision/transforms/functional_tensor.py:853(autocontrast)
     5922    0.020    0.000    0.664    0.000 /vision/torchvision/transforms/functional_tensor.py:534(_cast_squeeze_out)
    20000    0.019    0.000    0.027    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:161(tree_unflatten)
    20000    0.019    0.000    0.041    0.000 /vision/torchvision/prototype/transforms/_utils.py:94(_isinstance)
   230000    0.018    0.000    0.018    0.000 {method 'append' of 'list' objects}
     5000    0.017    0.000    0.831    0.000 /vision/torchvision/prototype/transforms/_meta.py:31(_transform)
    50314    0.016    0.000    0.016    0.000 /vision/torchvision/prototype/features/_feature.py:148(ndim)
     5000    0.016    0.000    0.596    0.000 /usr/local/lib/python3.8/dist-packages/torch/random.py:26(manual_seed)
    40712    0.016    0.000    0.029    0.000 /vision/torchvision/transforms/functional_tensor.py:9(_is_tensor_a_torch_image)
     5000    0.016    0.000    2.647    0.001 /vision/torchvision/prototype/features/_image.py:184(resized_crop)
     6052    0.016    0.000    4.897    0.001 /vision/torchvision/prototype/transforms/_auto_augment.py:60(_apply_image_transform)
    50000    0.016    0.000    0.016    0.000 /usr/lib/python3.8/traceback.py:292(walk_stack)
     5000    0.015    0.000    2.678    0.001 /vision/torchvision/prototype/transforms/_geometry.py:148(_transform)
     5000    0.014    0.000    0.047    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:34(_extract_image)
  540/270    0.014    0.000    0.015    0.000 {method 'amin' of 'torch._C._TensorBase' objects}
    45000    0.014    0.000    0.018    0.000 /usr/lib/python3.8/linecache.py:147(lazycache)
     5000    0.014    0.000    0.014    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}
    45000    0.014    0.000    0.017    0.000 /usr/lib/python3.8/linecache.py:37(getlines)
    46018    0.013    0.000    0.013    0.000 {built-in method builtins.issubclass}
  540/270    0.013    0.000    0.014    0.000 {method 'amax' of 'torch._C._TensorBase' objects}
    20000    0.013    0.000    0.021    0.000 /vision/torchvision/prototype/features/_feature.py:18(is_simple_tensor)
     5000    0.013    0.000    0.019    0.000 /usr/lib/python3.8/traceback.py:369(from_list)
4752/2376    0.013    0.000    0.025    0.000 {method 'size' of 'torch._C._TensorBase' objects}
    30000    0.013    0.000    0.041    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:96(_get_node_type)
     5000    0.013    0.000    2.662    0.001 /vision/torchvision/prototype/transforms/functional/_geometry.py:1192(resized_crop)
     5000    0.012    0.000    0.035    0.000 /vision/torchvision/prototype/features/_feature.py:65(<lambda>)
2186/1093    0.012    0.000    0.018    0.000 {method 'unbind' of 'torch._C._TensorBase' objects}
    10000    0.012    0.000    0.021    0.000 /usr/lib/python3.8/typing.py:255(inner)
     5000    0.012    0.000    0.021    0.000 /vision/torchvision/utils.py:538(_log_api_usage_once)
    45000    0.012    0.000    0.012    0.000 /usr/lib/python3.8/traceback.py:243(__init__)
    40712    0.011    0.000    0.040    0.000 /vision/torchvision/transforms/functional_tensor.py:13(_assert_image_tensor)
     5000    0.011    0.000    0.557    0.000 /usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:158(_lazy_call)
    51018    0.011    0.000    0.011    0.000 {method 'get' of 'dict' objects}
     5000    0.011    0.000    0.538    0.000 /usr/lib/python3.8/traceback.py:193(format_stack)
     5000    0.010    0.000    0.010    0.000 {built-in method builtins.getattr}
    90000    0.010    0.000    0.010    0.000 {method 'strip' of 'str' objects}
    10000    0.010    0.000    0.031    0.000 /usr/lib/python3.8/typing.py:802(__getitem__)
     2174    0.010    0.000    2.396    0.001 /vision/torchvision/transforms/functional_tensor.py:896(_equalize_single_image)
     5922    0.010    0.000    0.372    0.000 /vision/torchvision/transforms/functional_tensor.py:518(_cast_squeeze_in)
     5000    0.010    0.000    0.038    0.000 /usr/lib/python3.8/random.py:123(seed)
     5000    0.010    0.000    0.604    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:50(horizontal_flip)
     5000    0.010    0.000    0.592    0.000 /vision/torchvision/prototype/features/_image.py:156(horizontal_flip)
      546    0.009    0.000    0.023    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:165(<lambda>)
      715    0.009    0.000    0.902    0.001 /vision/torchvision/prototype/transforms/functional/_geometry.py:488(rotate_image_tensor)
     5000    0.009    0.000    0.364    0.000 /usr/lib/python3.8/traceback.py:200(extract_stack)
      369    0.009    0.000    0.009    0.000 {built-in method torch.mean}
     1047    0.009    0.000    0.103    0.000 /vision/torchvision/transforms/functional_tensor.py:774(invert)
     5000    0.009    0.000    2.605    0.001 /vision/torchvision/prototype/transforms/functional/_geometry.py:1139(resized_crop_image_tensor)
     5000    0.008    0.000    0.108    0.000 /vision/torchvision/prototype/transforms/_utils.py:80(query_chw)
    16324    0.008    0.000    0.008    0.000 /vision/torchvision/prototype/features/_feature.py:156(dtype)
     5000    0.008    0.000    0.067    0.000 /vision/torchvision/prototype/transforms/_utils.py:82(<setcomp>)
    30000    0.008    0.000    0.008    0.000 {built-in method builtins.sum}
    60000    0.008    0.000    0.008    0.000 {method 'dim' of 'torch._C._TensorBase' objects}
    10000    0.007    0.000    0.019    0.000 /vision/torchvision/prototype/features/_image.py:130(num_channels)
      711    0.007    0.000    0.480    0.001 /vision/torchvision/transforms/functional_tensor.py:801(solarize)
    45000    0.007    0.000    0.007    0.000 {method 'join' of 'str' objects}
     5000    0.007    0.000    0.007    0.000 {built-in method torch._C._log_api_usage_once}
     5000    0.006    0.000    0.049    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:55(_put_into_sample)
    10000    0.006    0.000    0.009    0.000 /usr/lib/python3.8/typing.py:720(__hash__)
     5000    0.006    0.000    0.006    0.000 /usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:50(queue_seed_all)
     2174    0.006    0.000    2.417    0.001 /vision/torchvision/transforms/functional_tensor.py:900(equalize)
     5000    0.006    0.000    0.563    0.000 /usr/local/lib/python3.8/dist-packages/torch/cuda/random.py:98(manual_seed_all)
     5000    0.006    0.000    0.162    0.000 /usr/lib/python3.8/traceback.py:27(format_list)
    12694    0.006    0.000    0.006    0.000 {built-in method builtins.round}
6642/5821    0.006    0.000    0.010    0.000 {method 'numel' of 'torch._C._TensorBase' objects}
      715    0.005    0.000    0.865    0.001 /vision/torchvision/transforms/functional_tensor.py:656(rotate)
    45000    0.005    0.000    0.005    0.000 {method 'add' of 'set' objects}
     2174    0.005    0.000    2.434    0.001 /vision/torchvision/prototype/features/_image.py:299(equalize)
    30000    0.005    0.000    0.005    0.000 {method 'keys' of 'dict' objects}
      546    0.005    0.000    0.041    0.000 /vision/torchvision/transforms/functional_tensor.py:787(posterize)
    30000    0.005    0.000    0.005    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:116(<listcomp>)
1295/1194    0.005    0.000    0.005    0.000 {method 'unsqueeze' of 'torch._C._TensorBase' objects}
     5821    0.005    0.000    0.006    0.000 /usr/lib/python3.8/types.py:171(__get__)
      821    0.005    0.000    0.748    0.001 /vision/torchvision/transforms/functional_tensor.py:547(_apply_grid_transform)
      821    0.005    0.000    0.007    0.000 /vision/torchvision/transforms/functional.py:987(_get_inverse_affine_matrix)
    16052    0.005    0.000    0.005    0.000 /vision/torchvision/prototype/features/_feature.py:130(_F)
      546    0.005    0.000    0.005    0.000 {built-in method torch.rsub}
      270    0.005    0.000    0.005    0.000 {built-in method torch.isfinite}
     2174    0.005    0.000    2.441    0.001 /vision/torchvision/prototype/transforms/functional/_color.py:126(equalize)
    36052    0.005    0.000    0.005    0.000 /usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py:1082(is_scripting)
     5000    0.005    0.000    0.559    0.000 /vision/torchvision/transforms/functional_tensor.py:126(hflip)
     7035    0.005    0.000    0.031    0.000 /vision/torchvision/transforms/functional_tensor.py:62(_assert_channels)
    10000    0.004    0.000    0.004    0.000 /vision/torchvision/prototype/transforms/_transform.py:26(_get_params)
2301/1561    0.004    0.000    0.007    0.000 {built-in method torch.is_floating_point}
      821    0.004    0.000    0.004    0.000 {method 'reshape' of 'torch._C._TensorBase' objects}
      724    0.004    0.000    0.369    0.001 /vision/torchvision/transforms/functional_tensor.py:230(adjust_saturation)
     5000    0.004    0.000    0.008    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:98(_compute_resized_output_size)
      821    0.004    0.000    0.004    0.000 {method 'transpose' of 'torch._C._TensorBase' objects}
      546    0.004    0.000    0.004    0.000 {built-in method torch.arange}
     5000    0.004    0.000    0.607    0.000 /vision/torchvision/prototype/transforms/_geometry.py:32(_transform)
  202/101    0.003    0.000    0.005    0.000 {method 'clone' of 'torch._C._TensorBase' objects}
      369    0.003    0.000    0.190    0.001 /vision/torchvision/transforms/functional_tensor.py:184(adjust_contrast)
     5000    0.003    0.000    0.006    0.000 /usr/local/lib/python3.8/dist-packages/torch/jit/_trace.py:1008(is_tracing)
      101    0.003    0.000    0.084    0.001 /vision/torchvision/transforms/functional_tensor.py:816(_blurred_degenerate_image)
     5000    0.003    0.000    0.004    0.000 main.py:92(friendly_to_image_tensor)
      270    0.003    0.000    0.004    0.000 /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:822(__rdiv__)
     5000    0.003    0.000    0.004    0.000 /vision/torchvision/transforms/functional.py:363(_compute_resized_output_size)
    10000    0.003    0.000    0.003    0.000 {built-in method builtins.hash}
     5000    0.003    0.000    0.003    0.000 {built-in method torch._C._is_tracing}
      821    0.002    0.000    0.002    0.000 {method 'unsqueeze_' of 'torch._C._TensorBase' objects}
    12694    0.002    0.000    0.002    0.000 {built-in method math.sqrt}
      711    0.002    0.000    0.486    0.001 /vision/torchvision/prototype/features/_image.py:291(solarize)
      715    0.002    0.000    0.908    0.001 /vision/torchvision/prototype/features/_image.py:208(rotate)
      724    0.002    0.000    0.375    0.001 /vision/torchvision/prototype/features/_image.py:267(adjust_saturation)
      711    0.002    0.000    0.489    0.001 /vision/torchvision/prototype/transforms/functional/_color.py:100(solarize)
     5000    0.002    0.000    0.002    0.000 {method 'startswith' of 'str' objects}
      724    0.002    0.000    0.378    0.001 /vision/torchvision/prototype/transforms/functional/_color.py:22(adjust_saturation)
     5000    0.002    0.000    0.002    0.000 {built-in method torch._C._cuda_isInBadFork}
      715    0.002    0.000    0.910    0.001 /vision/torchvision/prototype/transforms/functional/_geometry.py:616(rotate)
      546    0.002    0.000    0.002    0.000 {method 'round' of 'torch._C._TensorBase' objects}
      546    0.002    0.000    0.002    0.000 {method 'int' of 'torch._C._TensorBase' objects}
     5000    0.002    0.000    0.002    0.000 /vision/torchvision/transforms/functional_tensor.py:47(_max_value)
      821    0.002    0.000    0.623    0.001 /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4086(grid_sample)
      821    0.002    0.000    0.005    0.000 /vision/torchvision/transforms/functional_tensor.py:479(_assert_grid_transform_inputs)
      546    0.002    0.000    0.047    0.000 /vision/torchvision/prototype/transforms/functional/_color.py:87(posterize)
     5821    0.001    0.000    0.001    0.000 /usr/lib/python3.8/enum.py:753(value)
      106    0.001    0.000    0.131    0.001 /vision/torchvision/prototype/transforms/functional/_geometry.py:260(affine_image_tensor)
     5000    0.001    0.000    0.001    0.000 {built-in method torch._C._has_torch_function_unary}
      546    0.001    0.000    0.045    0.000 /vision/torchvision/prototype/features/_image.py:287(posterize)
    10546    0.001    0.000    0.001    0.000 /usr/lib/python3.8/typing.py:1149(cast)
     6052    0.001    0.000    0.001    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:435(_convert_fill_arg)
      336    0.001    0.000    0.037    0.000 /vision/torchvision/prototype/features/_image.py:303(invert)
      369    0.001    0.000    0.194    0.001 /vision/torchvision/prototype/features/_image.py:271(adjust_contrast)
      369    0.001    0.000    0.195    0.001 /vision/torchvision/prototype/transforms/functional/_color.py:35(adjust_contrast)
      270    0.001    0.000    0.001    0.000 {method 'logical_not' of 'torch._C._TensorBase' objects}
      270    0.001    0.000    0.124    0.000 /vision/torchvision/prototype/features/_image.py:295(autocontrast)
     5000    0.001    0.000    0.001    0.000 /usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:153(is_initialized)
     5000    0.001    0.000    0.001    0.000 {built-in method sys._getframe}
      816    0.001    0.000    0.011    0.000 /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:35(wrapped)
      270    0.001    0.000    0.001    0.000 {method 'reciprocal' of 'torch._C._TensorBase' objects}
      336    0.001    0.000    0.039    0.000 /vision/torchvision/prototype/transforms/functional/_color.py:139(invert)
     5000    0.001    0.000    0.001    0.000 {method 'reverse' of 'list' objects}
      711    0.001    0.000    0.008    0.000 /vision/torchvision/transforms/functional_tensor.py:18(_assert_threshold)
     5000    0.001    0.000    0.001    0.000 {method 'pop' of 'set' objects}
      101    0.001    0.000    0.124    0.001 /vision/torchvision/transforms/functional_tensor.py:839(adjust_sharpness)
     5747    0.001    0.000    0.001    0.000 {built-in method math.cos}
      101    0.001    0.000    0.001    0.000 {built-in method torch.ones}
      106    0.001    0.000    0.125    0.001 /vision/torchvision/transforms/functional_tensor.py:607(affine)
      270    0.001    0.000    0.125    0.000 /vision/torchvision/prototype/transforms/functional/_color.py:113(autocontrast)
      724    0.001    0.000    0.005    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:161(<lambda>)
      715    0.001    0.000    0.005    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:159(<lambda>)
      711    0.001    0.000    0.005    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:170(<lambda>)
      101    0.001    0.000    0.001    0.000 {method 'expand' of 'torch._C._TensorBase' objects}
      101    0.001    0.000    0.001    0.000 {method 'squeeze' of 'torch._C._TensorBase' objects}
      821    0.001    0.000    0.001    0.000 /vision/torchvision/transforms/functional.py:1027(<listcomp>)
     1148    0.001    0.000    0.001    0.000 /vision/torchvision/prototype/features/_feature.py:152(device)
      546    0.001    0.000    0.005    0.000 /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:818(__rsub__)
     2174    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:172(<lambda>)
      106    0.000    0.000    0.001    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:207(_affine_parse_args)
      106    0.000    0.000    0.132    0.001 /vision/torchvision/prototype/features/_image.py:221(affine)
      369    0.000    0.000    0.002    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:162(<lambda>)
      106    0.000    0.000    0.133    0.001 /vision/torchvision/prototype/transforms/functional/_geometry.py:449(affine)
     2463    0.000    0.000    0.000    0.000 {built-in method math.sin}
     2463    0.000    0.000    0.000    0.000 {built-in method math.radians}
      816    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function}
     1642    0.000    0.000    0.000    0.000 {built-in method math.tan}
      101    0.000    0.000    0.125    0.001 /vision/torchvision/prototype/transforms/functional/_color.py:48(adjust_sharpness)
      101    0.000    0.000    0.124    0.001 /vision/torchvision/prototype/features/_image.py:275(adjust_sharpness)
      821    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_variadic}
      212    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}
      101    0.000    0.000    0.001    0.000 /vision/torchvision/prototype/features/_feature.py:64(<lambda>)
      106    0.000    0.000    0.001    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:149(<lambda>)
      106    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:282(<listcomp>)
      101    0.000    0.000    0.001    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:163(<lambda>)
      212    0.000    0.000    0.000    0.000 /usr/lib/python3.8/abc.py:96(__instancecheck__)
      106    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:255(<listcomp>)
      336    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:173(<lambda>)
      106    0.000    0.000    0.000    0.000 {built-in method math.atan}
      270    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:171(<lambda>)
      106    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:284(<listcomp>)
      106    0.000    0.000    0.000    0.000 {built-in method math.degrees}
        1    0.000    0.000    0.000    0.000 /usr/lib/python3.8/cProfile.py:133(__exit__)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}


