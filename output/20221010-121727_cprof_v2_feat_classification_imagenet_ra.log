         1715037 function calls (1687908 primitive calls) in 6.366 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     2000    1.490    0.001    1.490    0.001 {built-in method torch._C._nn._upsample_bilinear2d_aa}
15505/13505    0.552    0.000    0.576    0.000 {method 'to' of 'torch._C._TensorBase' objects}
     2697    0.486    0.000    0.890    0.000 /vision/torchvision/transforms/functional_tensor.py:870(_scale_channel)
      309    0.236    0.001    0.236    0.001 {built-in method torch.grid_sampler}
4000/2000    0.209    0.000    0.222    0.000 {method 'flip' of 'torch._C._TensorBase' objects}
     2697    0.182    0.000    0.182    0.000 {built-in method torch.bincount}
4078/4039    0.172    0.000    0.172    0.000 {method 'clone' of 'torch._C._TensorBase' objects}
     2000    0.125    0.000    0.125    0.000 {method 'div' of 'torch._C._TensorBase' objects}
  600/300    0.110    0.000    0.111    0.000 {built-in method torch.where}
     2000    0.108    0.000    0.108    0.000 {method 'div_' of 'torch._C._TensorBase' objects}
     2348    0.103    0.000    0.103    0.000 {built-in method torch.round}
     2000    0.089    0.000    2.210    0.001 /vision/torchvision/prototype/transforms/_auto_augment.py:277(forward)
     4000    0.074    0.000    0.764    0.000 /vision/torchvision/prototype/transforms/_transform.py:66(forward)
    16747    0.073    0.000    0.767    0.000 /vision/torchvision/prototype/features/_feature.py:67(__torch_function__)
      454    0.070    0.000    0.093    0.000 /vision/torchvision/transforms/functional_tensor.py:150(rgb_to_grayscale)
     2000    0.068    0.000    0.155    0.000 /vision/torchvision/transforms/functional_tensor.py:938(erase)
14939/13731    0.060    0.000    0.064    0.000 {method 'view' of 'torch._C._TensorBase' objects}
     1798    0.057    0.000    0.057    0.000 {built-in method torch.stack}
     2000    0.056    0.000    0.056    0.000 {method 'sub_' of 'torch._C._TensorBase' objects}
     2000    0.055    0.000    0.177    0.000 /vision/torchvision/prototype/transforms/_augment.py:48(_get_params)
    10000    0.055    0.000    0.055    0.000 {built-in method torch.randint}
     8802    0.052    0.000    0.052    0.000 {built-in method torch.rand}
    12487    0.045    0.000    0.045    0.000 {method 'as_subclass' of 'torch._C._TensorBase' objects}
     5058    0.044    0.000    0.044    0.000 {built-in method torch.tensor}
     3292    0.041    0.000    0.041    0.000 {method 'clamp' of 'torch._C._TensorBase' objects}
     2000    0.041    0.000    0.339    0.000 /vision/torchvision/transforms/functional_tensor.py:912(normalize)
      532    0.041    0.000    0.041    0.000 {method 'mul' of 'torch._C._TensorBase' objects}
    10000    0.041    0.000    0.041    0.000 {built-in method posix.stat}
      493    0.040    0.000    0.142    0.000 /vision/torchvision/transforms/functional_tensor.py:264(_blend)
      300    0.040    0.000    0.040    0.000 {method 'ge' of 'torch._C._TensorBase' objects}
     2000    0.040    0.000    0.161    0.000 /vision/torchvision/prototype/transforms/_geometry.py:107(_get_params)
     2000    0.039    0.000    0.147    0.000 /usr/lib/python3.8/traceback.py:321(extract)
     8091    0.038    0.000    0.038    0.000 {built-in method torch.div}
16000/2000    0.038    0.000    6.103    0.003 /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1184(_call_impl)
     9064    0.037    0.000    0.037    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}
      542    0.036    0.000    0.036    0.000 {method 'sub' of 'torch._C._TensorBase' objects}
    12000    0.036    0.000    3.665    0.000 /vision/torchvision/prototype/transforms/_transform.py:32(forward)
     9373    0.035    0.000    0.035    0.000 {built-in method torch.empty}
      309    0.034    0.000    0.034    0.000 {method 'bmm' of 'torch._C._TensorBase' objects}
   197060    0.032    0.000    0.032    0.000 {built-in method builtins.isinstance}
     2000    0.031    0.000    6.095    0.003 /vision/torchvision/prototype/transforms/_container.py:15(forward)
     2000    0.031    0.000    0.055    0.000 /usr/lib/python3.8/traceback.py:388(format)
24000/22000    0.028    0.000    0.138    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:139(tree_flatten)
       39    0.028    0.001    0.028    0.001 {built-in method torch.conv2d}
    24000    0.028    0.000    0.037    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:112(__init__)
     2697    0.024    0.000    0.024    0.000 {built-in method torch.nn.functional.pad}
     9656    0.023    0.000    0.036    0.000 /vision/torchvision/transforms/functional_tensor.py:24(get_dimensions)
     4000    0.022    0.000    0.022    0.000 {built-in method torch.as_tensor}
     4532    0.021    0.000    0.021    0.000 {built-in method torch.exp}
    16899    0.020    0.000    0.020    0.000 {built-in method torch._C._get_tracing_state}
    22000    0.019    0.000    0.054    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:132(__init__)
    12000    0.019    0.000    3.204    0.000 /vision/torchvision/prototype/transforms/_transform.py:38(<listcomp>)
     2000    0.019    0.000    0.298    0.000 /vision/torchvision/transforms/functional_tensor.py:68(convert_image_dtype)
    24000    0.019    0.000    0.051    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:102(_is_leaf)
    26000    0.018    0.000    0.021    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:86(_is_namedtuple_instance)
      618    0.017    0.000    0.017    0.000 {method 'copy_' of 'torch._C._TensorBase' objects}
10670/7335    0.017    0.000    0.034    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}
     2736    0.016    0.000    0.016    0.000 {method 'sum' of 'torch._C._TensorBase' objects}
    17064    0.016    0.000    0.016    0.000 {method 'item' of 'torch._C._TensorBase' objects}
     2000    0.015    0.000    0.053    0.000 /vision/torchvision/transforms/functional_tensor.py:132(crop)
     2000    0.015    0.000    1.948    0.001 /vision/torchvision/prototype/transforms/functional/_geometry.py:119(resize_image_tensor)
      899    0.015    0.000    0.905    0.001 /vision/torchvision/transforms/functional_tensor.py:892(<listcomp>)
     2697    0.015    0.000    0.015    0.000 {built-in method torch.cumsum}
   138426    0.014    0.000    0.014    0.000 {built-in method builtins.len}
    16000    0.014    0.000    0.031    0.000 /vision/torchvision/prototype/transforms/_utils.py:101(_isinstance)
    14000    0.014    0.000    0.020    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:161(tree_unflatten)
    54000    0.014    0.000    0.034    0.000 /usr/lib/python3.8/traceback.py:285(line)
     2000    0.013    0.000    1.900    0.001 /vision/torchvision/transforms/functional_tensor.py:447(resize)
    36000    0.013    0.000    0.013    0.000 {method 'format' of 'str' objects}
     4000    0.013    0.000    0.029    0.000 /vision/torchvision/prototype/features/_image.py:108(image_size)
    18743    0.012    0.000    0.012    0.000 /vision/torchvision/prototype/features/_feature.py:138(shape)
     2000    0.012    0.000    0.012    0.000 {method 'any' of 'torch._C._TensorBase' objects}
     2000    0.012    0.000    0.359    0.000 /vision/torchvision/prototype/transforms/functional/_misc.py:16(normalize)
     2000    0.011    0.000    1.505    0.001 /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3765(interpolate)
      205    0.011    0.000    0.011    0.000 {method '__and__' of 'torch._C._TensorBase' objects}
     2000    0.011    0.000    0.321    0.000 /vision/torchvision/transforms/functional.py:211(convert_image_dtype)
     2000    0.011    0.000    0.011    0.000 {function Random.seed at 0x7ff929b47dc0}
    16747    0.010    0.000    0.023    0.000 {built-in method builtins.all}
     1720    0.010    0.000    0.010    0.000 {built-in method torch.linspace}
    10487    0.010    0.000    0.057    0.000 /vision/torchvision/prototype/features/_image.py:98(wrap_like)
      309    0.010    0.000    0.082    0.000 /vision/torchvision/transforms/functional_tensor.py:581(_gen_affine_grid)
    10000    0.010    0.000    0.051    0.000 /usr/lib/python3.8/linecache.py:53(checkcache)
    16000    0.010    0.000    0.016    0.000 /vision/torchvision/prototype/features/_feature.py:18(is_simple_tensor)
    21466    0.010    0.000    0.014    0.000 /vision/torchvision/transforms/functional_tensor.py:9(_is_tensor_a_torch_image)
1807/1353    0.010    0.000    0.012    0.000 {method 'unbind' of 'torch._C._TensorBase' objects}
    26000    0.009    0.000    0.030    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:96(_get_node_type)
    18000    0.009    0.000    0.018    0.000 /usr/lib/python3.8/linecache.py:15(getline)
     4000    0.009    0.000    0.049    0.000 /vision/torchvision/prototype/transforms/_utils.py:88(<setcomp>)
      309    0.009    0.000    0.009    0.000 {method 'fill_' of 'torch._C._TensorBase' objects}
     2348    0.008    0.000    0.268    0.000 /vision/torchvision/transforms/functional_tensor.py:534(_cast_squeeze_out)
      102    0.008    0.000    0.047    0.000 /vision/torchvision/transforms/functional_tensor.py:848(autocontrast)
     4000    0.008    0.000    0.036    0.000 /vision/torchvision/prototype/transforms/functional/_meta.py:14(get_dimensions)
    10487    0.008    0.000    0.047    0.000 /vision/torchvision/prototype/features/_image.py:65(_wrap)
      899    0.008    0.000    1.014    0.001 /vision/torchvision/prototype/transforms/functional/_color.py:186(equalize_image_tensor)
    33494    0.008    0.000    0.013    0.000 /vision/torchvision/prototype/features/_feature.py:95(<genexpr>)
    94000    0.008    0.000    0.008    0.000 {method 'append' of 'list' objects}
     2000    0.008    0.000    0.248    0.000 /usr/local/lib/python3.8/dist-packages/torch/random.py:26(manual_seed)
     2000    0.007    0.000    2.038    0.001 /vision/torchvision/prototype/transforms/_geometry.py:148(_transform)
     4000    0.007    0.000    0.077    0.000 /vision/torchvision/prototype/transforms/_utils.py:86(query_chw)
     2448    0.007    0.000    2.002    0.001 /vision/torchvision/prototype/transforms/_auto_augment.py:61(_apply_image_or_video_transform)
4494/3247    0.007    0.000    0.013    0.000 {method 'numel' of 'torch._C._TensorBase' objects}
     2000    0.007    0.000    2.025    0.001 /vision/torchvision/prototype/features/_image.py:166(resized_crop)
    21466    0.007    0.000    0.021    0.000 /vision/torchvision/transforms/functional_tensor.py:13(_assert_image_tensor)
     2000    0.007    0.000    0.020    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:34(_extract_image_or_video)
     2000    0.006    0.000    0.163    0.000 /vision/torchvision/prototype/transforms/functional/_augment.py:26(erase)
     2000    0.006    0.000    0.169    0.000 /vision/torchvision/prototype/transforms/_augment.py:95(_transform)
    20000    0.006    0.000    0.006    0.000 /usr/lib/python3.8/traceback.py:292(walk_stack)
    18673    0.006    0.000    0.006    0.000 /vision/torchvision/prototype/features/_feature.py:142(ndim)
    18000    0.006    0.000    0.007    0.000 /usr/lib/python3.8/linecache.py:147(lazycache)
     2000    0.006    0.000    0.419    0.000 /vision/torchvision/prototype/transforms/_misc.py:107(forward)
    18000    0.006    0.000    0.007    0.000 /usr/lib/python3.8/linecache.py:37(getlines)
     2000    0.006    0.000    0.006    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}
     2000    0.006    0.000    0.338    0.000 /vision/torchvision/prototype/transforms/_meta.py:31(_transform)
     4000    0.006    0.000    0.021    0.000 {built-in method builtins.getattr}
    24000    0.005    0.000    0.005    0.000 {built-in method builtins.sum}
  204/102    0.005    0.000    0.006    0.000 {method 'amin' of 'torch._C._TensorBase' objects}
     2000    0.005    0.000    0.009    0.000 /vision/torchvision/utils.py:538(_log_api_usage_once)
  204/102    0.005    0.000    0.006    0.000 {method 'amax' of 'torch._C._TensorBase' objects}
     2000    0.005    0.000    0.008    0.000 /usr/lib/python3.8/traceback.py:369(from_list)
     2000    0.005    0.000    2.031    0.001 /vision/torchvision/prototype/transforms/functional/_geometry.py:1331(resized_crop)
     4000    0.005    0.000    0.009    0.000 /usr/lib/python3.8/typing.py:255(inner)
    16747    0.005    0.000    0.005    0.000 {built-in method builtins.issubclass}
     2000    0.005    0.000    0.231    0.000 /usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:158(_lazy_call)
    18000    0.005    0.000    0.005    0.000 /usr/lib/python3.8/traceback.py:243(__init__)
     2000    0.005    0.000    0.152    0.000 /usr/lib/python3.8/traceback.py:200(extract_stack)
     2000    0.005    0.000    0.222    0.000 /usr/lib/python3.8/traceback.py:193(format_stack)
    36000    0.005    0.000    0.005    0.000 {method 'strip' of 'str' objects}
     2000    0.004    0.000    0.248    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:59(horizontal_flip)
     4000    0.004    0.000    0.013    0.000 /usr/lib/python3.8/typing.py:802(__getitem__)
     2348    0.004    0.000    0.164    0.000 /vision/torchvision/transforms/functional_tensor.py:518(_cast_squeeze_in)
      899    0.004    0.000    0.940    0.001 /vision/torchvision/transforms/functional_tensor.py:891(_equalize_single_image)
     9064    0.004    0.000    0.004    0.000 {built-in method builtins.round}
    24000    0.004    0.000    0.004    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:116(<listcomp>)
     2000    0.004    0.000    0.243    0.000 /vision/torchvision/prototype/features/_image.py:138(horizontal_flip)
      162    0.004    0.000    0.004    0.000 {built-in method torch.mean}
     2000    0.004    0.000    0.022    0.000 /vision/torchvision/prototype/transforms/functional/_meta.py:58(get_spatial_size)
      440    0.004    0.000    0.044    0.000 /vision/torchvision/transforms/functional_tensor.py:769(invert)
     2000    0.004    0.000    2.005    0.001 /vision/torchvision/prototype/transforms/functional/_geometry.py:1263(resized_crop_image_tensor)
    18747    0.004    0.000    0.004    0.000 {method 'get' of 'dict' objects}
    24000    0.004    0.000    0.004    0.000 {method 'keys' of 'dict' objects}
     2000    0.004    0.000    0.015    0.000 /usr/lib/python3.8/random.py:123(seed)
      205    0.004    0.000    0.009    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:166(<lambda>)
      270    0.004    0.000    0.344    0.001 /vision/torchvision/prototype/transforms/functional/_geometry.py:542(rotate_image_tensor)
     6593    0.003    0.000    0.003    0.000 /vision/torchvision/prototype/features/_feature.py:150(dtype)
     8000    0.003    0.000    0.003    0.000 /vision/torchvision/prototype/transforms/_transform.py:26(_get_params)
    24899    0.003    0.000    0.003    0.000 {method 'dim' of 'torch._C._TensorBase' objects}
      300    0.003    0.000    0.190    0.001 /vision/torchvision/transforms/functional_tensor.py:796(solarize)
     2000    0.003    0.000    0.362    0.000 /vision/torchvision/prototype/transforms/_misc.py:104(_transform)
     2000    0.003    0.000    0.234    0.000 /usr/local/lib/python3.8/dist-packages/torch/cuda/random.py:98(manual_seed_all)
     2000    0.003    0.000    0.003    0.000 /usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:50(queue_seed_all)
     2000    0.003    0.000    0.021    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:56(_put_into_sample)
     2000    0.003    0.000    0.003    0.000 {built-in method torch._C._log_api_usage_once}
    20448    0.003    0.000    0.003    0.000 /usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py:1082(is_scripting)
    18000    0.003    0.000    0.003    0.000 {method 'join' of 'str' objects}
     4000    0.003    0.000    0.004    0.000 /usr/lib/python3.8/typing.py:720(__hash__)
     2000    0.002    0.000    0.065    0.000 /usr/lib/python3.8/traceback.py:27(format_list)
    18000    0.002    0.000    0.002    0.000 {method 'add' of 'set' objects}
     2309    0.002    0.000    0.003    0.000 /usr/lib/python3.8/types.py:171(__get__)
     6448    0.002    0.000    0.002    0.000 /vision/torchvision/prototype/features/_feature.py:124(_F)
      270    0.002    0.000    0.330    0.001 /vision/torchvision/transforms/functional_tensor.py:656(rotate)
     2000    0.002    0.000    0.030    0.000 /vision/torchvision/prototype/transforms/_utils.py:108(has_any)
      899    0.002    0.000    1.021    0.001 /vision/torchvision/prototype/features/_image.py:281(equalize)
      205    0.002    0.000    0.016    0.000 /vision/torchvision/transforms/functional_tensor.py:782(posterize)
  532/493    0.002    0.000    0.002    0.000 {method 'unsqueeze' of 'torch._C._TensorBase' objects}
     2000    0.002    0.000    0.228    0.000 /vision/torchvision/transforms/functional_tensor.py:126(hflip)
      899    0.002    0.000    1.024    0.001 /vision/torchvision/prototype/transforms/functional/_color.py:215(equalize)
     2000    0.002    0.000    0.013    0.000 /vision/torchvision/prototype/features/_feature.py:61(<lambda>)
      309    0.002    0.000    0.003    0.000 /vision/torchvision/transforms/functional.py:987(_get_inverse_affine_matrix)
     2000    0.002    0.000    0.004    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:111(_compute_resized_output_size)
      309    0.002    0.000    0.284    0.001 /vision/torchvision/transforms/functional_tensor.py:547(_apply_grid_transform)
      102    0.002    0.000    0.002    0.000 {built-in method torch.isfinite}
      899    0.002    0.000    0.008    0.000 /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:892(__iter__)
      205    0.002    0.000    0.002    0.000 {built-in method torch.rsub}
     9064    0.002    0.000    0.002    0.000 {built-in method math.sqrt}
  915/612    0.002    0.000    0.003    0.000 {built-in method torch.is_floating_point}
      292    0.002    0.000    0.152    0.001 /vision/torchvision/transforms/functional_tensor.py:230(adjust_saturation)
     2000    0.002    0.000    0.004    0.000 /vision/torchvision/prototype/features/_image.py:112(num_channels)
      309    0.002    0.000    0.002    0.000 {method 'reshape' of 'torch._C._TensorBase' objects}
     2000    0.002    0.000    0.003    0.000 /usr/local/lib/python3.8/dist-packages/torch/jit/_trace.py:1008(is_tracing)
     2000    0.002    0.000    0.249    0.000 /vision/torchvision/prototype/transforms/_geometry.py:32(_transform)
      205    0.002    0.000    0.002    0.000 {built-in method torch.arange}
      162    0.001    0.000    0.084    0.001 /vision/torchvision/transforms/functional_tensor.py:184(adjust_contrast)
      309    0.001    0.000    0.001    0.000 {method 'transpose' of 'torch._C._TensorBase' objects}
      899    0.001    0.000    0.942    0.001 /vision/torchvision/prototype/transforms/functional/_color.py:200(<listcomp>)
       39    0.001    0.000    0.041    0.001 /vision/torchvision/transforms/functional_tensor.py:811(_blurred_degenerate_image)
     1955    0.001    0.000    0.008    0.000 /vision/torchvision/transforms/functional_tensor.py:62(_assert_channels)
     2000    0.001    0.000    0.002    0.000 /vision/torchvision/transforms/functional.py:363(_compute_resized_output_size)
     4000    0.001    0.000    0.001    0.000 {built-in method builtins.hash}
      102    0.001    0.000    0.002    0.000 /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:822(__rdiv__)
     2000    0.001    0.000    0.001    0.000 {built-in method torch._C._is_tracing}
     2000    0.001    0.000    0.001    0.000 /usr/local/lib/python3.8/dist-packages/torch/utils/_pytree.py:59(_tuple_flatten)
      309    0.001    0.000    0.001    0.000 {method 'unsqueeze_' of 'torch._C._TensorBase' objects}
     2000    0.001    0.000    0.001    0.000 /vision/torchvision/transforms/functional_tensor.py:47(_max_value)
     2000    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_isInBadFork}
     2000    0.001    0.000    0.001    0.000 {method 'startswith' of 'str' objects}
      270    0.001    0.000    0.347    0.001 /vision/torchvision/prototype/features/_image.py:190(rotate)
      300    0.001    0.000    0.193    0.001 /vision/torchvision/prototype/features/_image.py:273(solarize)
      292    0.001    0.000    0.154    0.001 /vision/torchvision/prototype/features/_image.py:249(adjust_saturation)
      292    0.001    0.000    0.155    0.001 /vision/torchvision/prototype/transforms/functional/_color.py:32(adjust_saturation)
      300    0.001    0.000    0.194    0.001 /vision/torchvision/prototype/transforms/functional/_color.py:160(solarize)
      205    0.001    0.000    0.001    0.000 {method 'round' of 'torch._C._TensorBase' objects}
      270    0.001    0.000    0.348    0.001 /vision/torchvision/prototype/transforms/functional/_geometry.py:673(rotate)
     4000    0.001    0.000    0.001    0.000 {method 'pop' of 'set' objects}
      205    0.001    0.000    0.001    0.000 {method 'int' of 'torch._C._TensorBase' objects}
      309    0.001    0.000    0.002    0.000 /vision/torchvision/transforms/functional_tensor.py:479(_assert_grid_transform_inputs)
      899    0.001    0.000    0.001    0.000 {method 'size' of 'torch._C._TensorBase' objects}
      309    0.001    0.000    0.237    0.001 /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4086(grid_sample)
     2309    0.001    0.000    0.001    0.000 /usr/lib/python3.8/enum.py:753(value)
     2000    0.001    0.000    0.001    0.000 {built-in method torch._C._has_torch_function_unary}
     4205    0.001    0.000    0.001    0.000 /usr/lib/python3.8/typing.py:1149(cast)
      205    0.001    0.000    0.018    0.000 /vision/torchvision/prototype/transforms/functional/_color.py:143(posterize)
       39    0.001    0.000    0.049    0.001 /vision/torchvision/prototype/transforms/functional/_geometry.py:283(affine_image_tensor)
      205    0.001    0.000    0.018    0.000 /vision/torchvision/prototype/features/_image.py:269(posterize)
     2448    0.001    0.000    0.001    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:489(_convert_fill_arg)
      162    0.001    0.000    0.085    0.001 /vision/torchvision/prototype/features/_image.py:253(adjust_contrast)
      140    0.000    0.000    0.016    0.000 /vision/torchvision/prototype/features/_image.py:285(invert)
      162    0.000    0.000    0.086    0.001 /vision/torchvision/prototype/transforms/functional/_color.py:49(adjust_contrast)
      102    0.000    0.000    0.000    0.000 {method 'logical_not' of 'torch._C._TensorBase' objects}
     2000    0.000    0.000    0.000    0.000 {built-in method sys._getframe}
      102    0.000    0.000    0.000    0.000 {method 'reciprocal' of 'torch._C._TensorBase' objects}
      307    0.000    0.000    0.004    0.000 /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:35(wrapped)
     2000    0.000    0.000    0.000    0.000 /usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:153(is_initialized)
      102    0.000    0.000    0.048    0.000 /vision/torchvision/prototype/features/_image.py:277(autocontrast)
       39    0.000    0.000    0.055    0.001 /vision/torchvision/prototype/transforms/functional/_color.py:58(adjust_sharpness_image_tensor)
     2000    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}
     2163    0.000    0.000    0.000    0.000 {built-in method math.cos}
      140    0.000    0.000    0.016    0.000 /vision/torchvision/prototype/transforms/functional/_color.py:232(invert)
       39    0.000    0.000    0.000    0.000 {built-in method torch.ones}
      300    0.000    0.000    0.002    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:171(<lambda>)
       39    0.000    0.000    0.046    0.001 /vision/torchvision/transforms/functional_tensor.py:607(affine)
      270    0.000    0.000    0.002    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:160(<lambda>)
      292    0.000    0.000    0.002    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:162(<lambda>)
      300    0.000    0.000    0.003    0.000 /vision/torchvision/transforms/functional_tensor.py:18(_assert_threshold)
      479    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/features/_feature.py:146(device)
       39    0.000    0.000    0.000    0.000 {method 'squeeze' of 'torch._C._TensorBase' objects}
      102    0.000    0.000    0.048    0.000 /vision/torchvision/prototype/transforms/functional/_color.py:177(autocontrast)
      309    0.000    0.000    0.000    0.000 /vision/torchvision/transforms/functional.py:1027(<listcomp>)
      205    0.000    0.000    0.002    0.000 /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:818(__rsub__)
       39    0.000    0.000    0.000    0.000 {method 'expand' of 'torch._C._TensorBase' objects}
      899    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:173(<lambda>)
      899    0.000    0.000    0.000    0.000 {built-in method builtins.iter}
       39    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:230(_affine_parse_args)
      162    0.000    0.000    0.001    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:163(<lambda>)
       39    0.000    0.000    0.049    0.001 /vision/torchvision/prototype/features/_image.py:203(affine)
      618    0.000    0.000    0.000    0.000 {built-in method math.tan}
      927    0.000    0.000    0.000    0.000 {built-in method math.sin}
      927    0.000    0.000    0.000    0.000 {built-in method math.radians}
       39    0.000    0.000    0.056    0.001 /vision/torchvision/prototype/features/_image.py:257(adjust_sharpness)
       39    0.000    0.000    0.049    0.001 /vision/torchvision/prototype/transforms/functional/_geometry.py:503(affine)
       39    0.000    0.000    0.056    0.001 /vision/torchvision/prototype/transforms/functional/_color.py:92(adjust_sharpness)
      307    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function}
      309    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_variadic}
       78    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}
       39    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/features/_feature.py:60(<lambda>)
       39    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:150(<lambda>)
       39    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:164(<lambda>)
       39    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:278(<listcomp>)
       39    0.000    0.000    0.000    0.000 {built-in method math.atan}
       39    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:305(<listcomp>)
      140    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:174(<lambda>)
       78    0.000    0.000    0.000    0.000 /usr/lib/python3.8/abc.py:96(__instancecheck__)
      102    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/_auto_augment.py:172(<lambda>)
       39    0.000    0.000    0.000    0.000 /vision/torchvision/prototype/transforms/functional/_geometry.py:307(<listcomp>)
       39    0.000    0.000    0.000    0.000 {built-in method math.degrees}
        1    0.000    0.000    0.000    0.000 /usr/lib/python3.8/cProfile.py:133(__exit__)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}


